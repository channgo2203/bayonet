\hypertarget{classbayonet_1_1_gibbs_sampler}{\section{bayonet\-:\-:Gibbs\-Sampler Class Reference}
\label{classbayonet_1_1_gibbs_sampler}\index{bayonet\-::\-Gibbs\-Sampler@{bayonet\-::\-Gibbs\-Sampler}}
}


Implementation of the Gibbs sampler.  




{\ttfamily \#include $<$Gibbs\-Sampler.\-h$>$}

\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
std\-::vector$<$ unsigned int $>$ \hyperlink{classbayonet_1_1_gibbs_sampler_ac789fc64fd349769633ab84ea5e59f70}{Return\-Sample} (\hyperlink{classbayonet_1_1_bayesnet}{bayonet\-::\-Bayesnet} \&net)
\item 
std\-::vector$<$ std\-::vector\\*
$<$ unsigned int $>$ $>$ \hyperlink{classbayonet_1_1_gibbs_sampler_a625b16c10dc1d4fea3899fd5a0b3c921}{Accumulate\-Samples} (\hyperlink{classbayonet_1_1_bayesnet}{Bayesnet} \&net, unsigned int cycles)
\item 
void \hyperlink{classbayonet_1_1_gibbs_sampler_af375d044a2e0c45a384f37ee4761a2ba}{Print\-Sample} (\hyperlink{classbayonet_1_1_bayesnet}{bayonet\-::\-Bayesnet} \&net, unsigned int cycles=1)
\item 
\hyperlink{classbayonet_1_1_joint_probability_table}{Joint\-Probability\-Table} \hyperlink{classbayonet_1_1_gibbs_sampler_a29dfcfda3462de83fa89672768d690f4}{Return\-Joint\-Probability\-Table} (\hyperlink{classbayonet_1_1_bayesnet}{bayonet\-::\-Bayesnet} \&net, unsigned int cycles)
\end{DoxyCompactItemize}


\subsection{Detailed Description}
Implementation of the Gibbs sampler. 

The Gibbs sampler is part of the Markov Chain Monte Carlo (M\-C\-M\-C) methods. These family of methods work differently from rejection and L\-W sampling. Each sample is generated by making a random change to the preceding one. The algorithm starts with a random state where only the evidence variables are fixed at their observed values. After the initialization, the sampling is done conditioned on the current values of the variables in the Markov blanket of the node. The algorithm then continue moving at random, flipping one variable at a time but leaving the evidences unchanged. 

\subsection{Member Function Documentation}
\hypertarget{classbayonet_1_1_gibbs_sampler_a625b16c10dc1d4fea3899fd5a0b3c921}{\index{bayonet\-::\-Gibbs\-Sampler@{bayonet\-::\-Gibbs\-Sampler}!Accumulate\-Samples@{Accumulate\-Samples}}
\index{Accumulate\-Samples@{Accumulate\-Samples}!bayonet::GibbsSampler@{bayonet\-::\-Gibbs\-Sampler}}
\subsubsection[{Accumulate\-Samples}]{\setlength{\rightskip}{0pt plus 5cm}std\-::vector$<$ std\-::vector$<$ unsigned int $>$ $>$ bayonet\-::\-Gibbs\-Sampler\-::\-Accumulate\-Samples (
\begin{DoxyParamCaption}
\item[{{\bf Bayesnet} \&}]{net, }
\item[{unsigned int}]{cycles}
\end{DoxyParamCaption}
)}}\label{classbayonet_1_1_gibbs_sampler_a625b16c10dc1d4fea3899fd5a0b3c921}
This method is different from the same methods in the other samplers. A Markov chain is used for picking up samples in


\begin{DoxyParams}{Parameters}
{\em net} & the Bayesian network to use for picking up the sample. \\
\hline
{\em cycles} & the number of iterations \\
\hline
\end{DoxyParams}
\hypertarget{classbayonet_1_1_gibbs_sampler_af375d044a2e0c45a384f37ee4761a2ba}{\index{bayonet\-::\-Gibbs\-Sampler@{bayonet\-::\-Gibbs\-Sampler}!Print\-Sample@{Print\-Sample}}
\index{Print\-Sample@{Print\-Sample}!bayonet::GibbsSampler@{bayonet\-::\-Gibbs\-Sampler}}
\subsubsection[{Print\-Sample}]{\setlength{\rightskip}{0pt plus 5cm}void bayonet\-::\-Gibbs\-Sampler\-::\-Print\-Sample (
\begin{DoxyParamCaption}
\item[{{\bf bayonet\-::\-Bayesnet} \&}]{net, }
\item[{unsigned int}]{cycles = {\ttfamily 1}}
\end{DoxyParamCaption}
)}}\label{classbayonet_1_1_gibbs_sampler_af375d044a2e0c45a384f37ee4761a2ba}
It prints the result of the sampling. It is possible to do it for different iterations.


\begin{DoxyParams}{Parameters}
{\em net} & the Bayesian network to use for picking up the sample. \\
\hline
{\em cycles} & the number of iterations \\
\hline
\end{DoxyParams}
\hypertarget{classbayonet_1_1_gibbs_sampler_a29dfcfda3462de83fa89672768d690f4}{\index{bayonet\-::\-Gibbs\-Sampler@{bayonet\-::\-Gibbs\-Sampler}!Return\-Joint\-Probability\-Table@{Return\-Joint\-Probability\-Table}}
\index{Return\-Joint\-Probability\-Table@{Return\-Joint\-Probability\-Table}!bayonet::GibbsSampler@{bayonet\-::\-Gibbs\-Sampler}}
\subsubsection[{Return\-Joint\-Probability\-Table}]{\setlength{\rightskip}{0pt plus 5cm}{\bf Joint\-Probability\-Table} bayonet\-::\-Gibbs\-Sampler\-::\-Return\-Joint\-Probability\-Table (
\begin{DoxyParamCaption}
\item[{{\bf bayonet\-::\-Bayesnet} \&}]{net, }
\item[{unsigned int}]{cycles}
\end{DoxyParamCaption}
)}}\label{classbayonet_1_1_gibbs_sampler_a29dfcfda3462de83fa89672768d690f4}
It creates a Joint Probability table starting from the Bayesian network and sampling for the number of iterations specified.


\begin{DoxyParams}{Parameters}
{\em net} & the Bayesian network to use for picking up the sample. \\
\hline
{\em cycles} & the number of iterations \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
it return a Joint Probability Table object 
\end{DoxyReturn}
\hypertarget{classbayonet_1_1_gibbs_sampler_ac789fc64fd349769633ab84ea5e59f70}{\index{bayonet\-::\-Gibbs\-Sampler@{bayonet\-::\-Gibbs\-Sampler}!Return\-Sample@{Return\-Sample}}
\index{Return\-Sample@{Return\-Sample}!bayonet::GibbsSampler@{bayonet\-::\-Gibbs\-Sampler}}
\subsubsection[{Return\-Sample}]{\setlength{\rightskip}{0pt plus 5cm}std\-::vector$<$ unsigned int $>$ bayonet\-::\-Gibbs\-Sampler\-::\-Return\-Sample (
\begin{DoxyParamCaption}
\item[{{\bf bayonet\-::\-Bayesnet} \&}]{net}
\end{DoxyParamCaption}
)}}\label{classbayonet_1_1_gibbs_sampler_ac789fc64fd349769633ab84ea5e59f70}
It returns a single sample picking up it from the Bayesian network


\begin{DoxyParams}{Parameters}
{\em net} & the Bayesian network to use for picking up the sample. \\
\hline
\end{DoxyParams}


The documentation for this class was generated from the following files\-:\begin{DoxyCompactItemize}
\item 
include/Gibbs\-Sampler.\-h\item 
src/Gibbs\-Sampler.\-cpp\end{DoxyCompactItemize}
